# Is this mean?

[isthismean.com](https://isthismean.com/) uses a Tensorflow.js ML model to detect text toxicity using client side js. A user can submit their own text to be analyzed for toxicity.

## Reference Links

- https://github.com/conversationai/conversationai.github.io/blob/main/crowdsourcing_annotation_schemes/toxicity_with_subattributes.md
- https://github.com/tensorflow/tfjs-models/tree/master/toxicity
- https://www.tensorflow.org/js/guide/platform_environment

## Dev Stack

Vue 3 + Typescript + Vite

## Recommended IDE Setup

- [VSCode](https://code.visualstudio.com/) + [Volar](https://marketplace.visualstudio.com/items?itemName=johnsoncodehk.volar)
